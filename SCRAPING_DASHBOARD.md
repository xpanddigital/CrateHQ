# Scraping Dashboard - Complete Implementation

## ðŸŽ¯ Overview

Admin-only 4-step artist import pipeline that chains 3 Apify scrapers and intelligently merges results. Discovers artists, scrapes detailed data, enriches with genres, and imports with deduplication.

## âœ… Features Implemented

### 1. Scraping Dashboard Page âœ…
**Location**: `/scraping` (Admin only)

**4-Step Pipeline**:

#### Step 1: Discover Artists
- Enter keywords (comma-separated)
- Set max results per keyword
- OR paste Spotify URLs directly
- OR upload CSV of URLs
- Runs: `scrapearchitect/spotify-artist-scraper`
- Shows: "Found X artist URLs"

#### Step 2: Core Data Scrape
- Takes URLs from Step 1
- Runs: `beatanalytics/spotify-play-count-scraper`
- Scrapes:
  - Streaming data
  - Monthly listeners
  - Social links
  - Biography
  - Top cities
  - Albums & singles
  - Top tracks with stream counts
- Polls for completion
- Stores keyed by Spotify ID

#### Step 3: Genre Enrichment (Optional)
- Takes same URLs
- Runs: `web-scraper/spotify-scraper`
- Scrapes:
  - Genres
  - Popularity score
- Merges with Step 2 data
- Can skip this step

#### Step 4: Review & Import
- Preview table with columns:
  - Name
  - Monthly Listeners
  - Top Track Streams
  - Track Count
  - Genres
  - Has Instagram
  - Has YouTube
  - Has Website
  - Has Bio
- Summary stats at top
- Deselect rows option
- Tag selector (auto-apply on import)
- Import button
- Deduplicates by `spotify_url`
- Shows: imported / skipped / failed

---

### 2. Data Transformation âœ…

**Apify Fields â†’ Database Fields**:

```typescript
// Basic Info
name â†’ name
_url â†’ spotify_url
monthlyListeners â†’ spotify_monthly_listeners
followers â†’ (stored separately, NOT instagram_followers)
biography â†’ biography
coverArt/0/url â†’ image_url
topCities/0/country â†’ country

// Social Links (built from externalLinks array)
externalLinks/N/label + externalLinks/N/url â†’ social_links JSON
{
  "instagram": "url",
  "youtube": "url", 
  "facebook": "url",
  "twitter": "url",
  "wikipedia": "url",
  "verified": true/false,
  "world_rank": number
}

// Instagram Handle
Extract from Instagram URL â†’ instagram_handle
(strips https://instagram.com/ and trailing slash)

// Track Count
Count albums/N/id + singles/N/id â†’ track_count

// Streams
Sum topTracks/N/streamCount â†’ streams_last_month

// Genres (from Step 3)
genres array â†’ genres (JSONB)

// Metadata
verified â†’ social_links.verified
worldRank â†’ social_links.world_rank
```

---

### 3. API Routes âœ…

**POST /api/scraping/discover**:
- Takes: `{ keywords, maxResults }`
- Runs discovery scraper
- Polls for completion
- Returns: `{ urls: [...] }`

**POST /api/scraping/core-data**:
- Takes: `{ urls }`
- Runs play count scraper
- Transforms data
- Returns: `{ results: { spotifyId: {...} } }`

**POST /api/scraping/genres**:
- Takes: `{ urls }`
- Runs genre scraper
- Returns: `{ results: { spotifyId: { genres, popularity } } }`

**POST /api/scraping/import**:
- Takes: `{ artists, tagIds }`
- Checks for duplicates by `spotify_url`
- Transforms to database format
- Bulk inserts
- Applies tags
- Returns: `{ imported, skipped, failed }`

---

### 4. Settings Configuration âœ…

**Location**: `/settings` â†’ "Apify Scrapers" section (Admin only)

**Fields**:
- Apify API Token (password field)
- Discovery Actor ID (default: scrapearchitect/spotify-artist-scraper)
- Core Data Actor ID (default: beatanalytics/spotify-play-count-scraper)
- Genres Actor ID (default: web-scraper/spotify-scraper)
- Save button

**Storage**:
- Saved to `integrations` table
- `service = 'apify'`
- `api_key = token`
- `config = { discovery_actor, core_data_actor, genres_actor }`

---

### 5. Sidebar Integration âœ…

**Navigation**:
- "Scraping" link added to sidebar
- Icon: Download
- Visible to admin role only
- Positioned between Inbox and Analytics

---

## ðŸŽ¨ UI Features

### Stepper Component
- Visual progress indicator
- 4 steps with icons
- Checkmarks for completed steps
- Current step highlighted
- Arrows between steps

### Step 1 UI
- Keyword input
- Max results input
- "OR" divider
- Paste URLs textarea
- CSV upload option
- "Start Discovery" button
- Success card with count

### Step 2 UI
- URL count display
- Progress indicator
- "Scrape Core Data" button
- Success card with count

### Step 3 UI
- Optional step indicator
- "Skip This Step" button
- "Enrich Genres" button
- Progress indicator

### Step 4 UI
- Summary statistics (4 metrics)
- Tag selector (multi-select badges)
- Preview table with checkboxes
- Select all option
- Social badges (IG, YT, Web)
- Import button with count
- Success card with breakdown

---

## ðŸ”„ Complete Workflow

### Scenario 1: Keyword Discovery
```
1. Go to /scraping (admin only)
2. Enter: "indie hip hop, alternative R&B"
3. Set max: 50
4. Click "Start Discovery"
5. Wait ~30 seconds
6. See: "Found 100 artist URLs"
7. Click "Scrape Core Data"
8. Wait ~2 minutes
9. See: "Scraped 100 artists"
10. Click "Enrich Genres" (or skip)
11. Wait ~1 minute
12. Review table
13. Select tags: "hip-hop", "batch-feb-2026"
14. Click "Import 100 Artists"
15. See: "95 imported, 5 duplicates, 0 failed"
```

### Scenario 2: Direct URL Import
```
1. Go to /scraping
2. Paste 10 Spotify artist URLs
3. Click "Start Discovery"
4. Immediately proceeds to Step 2
5. Continue as above
```

### Scenario 3: Skip Genre Enrichment
```
1. Complete Steps 1-2
2. On Step 3, click "Skip This Step"
3. Goes directly to Step 4
4. Genres will be empty arrays
5. Import proceeds normally
```

---

## ðŸ”§ Technical Details

### Polling Strategy
- 5-second intervals
- Max 60 attempts for discovery (5 minutes)
- Max 120 attempts for core/genres (10 minutes)
- Graceful timeout handling

### Deduplication
- Queries existing artists by `spotify_url`
- Filters out matches before insert
- Counts as "skipped duplicates"
- No data overwritten

### Data Merging
- Core data keyed by Spotify ID
- Genre data keyed by Spotify ID
- Merged in Step 4 preparation
- Missing genre data = empty array

### Social Links Extraction
- Loops through `externalLinks/N/*` columns
- Builds JSON object
- Normalizes labels (lowercase, underscores)
- Stores Instagram, YouTube, Facebook, Twitter, Wikipedia

### Instagram Handle Extraction
```typescript
// Input: "https://www.instagram.com/champagnepapi/"
// Output: "champagnepapi"

handle = url
  .replace(/https?:\/\/(www\.)?instagram\.com\//gi, '')
  .replace(/\/$/, '')
  .split('/')[0]
```

### Track Counting
```typescript
let count = 0
for (let i = 0; i < 100; i++) {
  if (item[`albums/${i}/id`]) count++
  if (item[`singles/${i}/id`]) count++
}
```

### Stream Aggregation
```typescript
let total = 0
for (let i = 0; i < 10; i++) {
  total += parseInt(item[`topTracks/${i}/streamCount`]) || 0
}
// Use as streams_last_month proxy
```

---

## ðŸ’° Cost Analysis

### Apify Costs (Approximate)
- **Discovery**: $0.10 per 100 artists
- **Core Data**: $0.50 per 100 artists
- **Genres**: $0.20 per 100 artists
- **Total**: ~$0.80 per 100 artists

### Free Tier
- Apify: $5 free credit
- Can scrape ~600 artists for free
- Then pay-as-you-go

### Comparison
- **Manual entry**: 5 minutes per artist
- **This pipeline**: 3-5 minutes for 100 artists
- **Time saved**: 99%+

---

## ðŸ“Š Expected Data Quality

### From Core Data Scraper
- **Monthly Listeners**: 100% coverage
- **Social Links**: ~80% have at least one
- **Instagram**: ~60% coverage
- **YouTube**: ~40% coverage
- **Biography**: ~50% coverage
- **Track Count**: 100% coverage

### From Genre Scraper
- **Genres**: 100% coverage
- **Popularity**: 100% coverage

### Combined Quality
- **Email-findable**: ~70% (have website or bio)
- **Contactable after enrichment**: ~50% (72% of email-findable)

---

## ðŸŽ¯ Best Practices

### Keyword Strategy
- Use specific genres: "indie hip hop" not just "hip hop"
- Combine genre + descriptor: "underground rap", "alternative R&B"
- Test with small max (10-20) first
- Scale up after validating results

### URL Management
- Save discovered URLs before proceeding
- Can re-run Steps 2-3 with same URLs
- Keep URLs for future re-scraping

### Tag Strategy
- Create batch tags: "apify-feb-2026"
- Add genre tags: "hip-hop", "indie"
- Add quality tags: "high-streams", "verified"

### Import Strategy
- Review data quality before importing
- Deselect artists with missing data
- Import in batches of 100-200
- Run enrichment immediately after

---

## âš ï¸ Important Notes

### Rate Limiting
- Apify handles rate limiting internally
- No need for delays between steps
- Can run multiple pipelines simultaneously

### Data Freshness
- Spotify data updates daily
- Re-scrape every 30-60 days
- Streaming numbers change frequently

### Duplicate Handling
- Checks `spotify_url` only
- Does NOT update existing artists
- Skips count shown in results
- Manual merge if needed

### Error Handling
- Timeout after max attempts
- Failed artists logged
- Partial success supported
- Can retry failed batches

---

## ðŸš€ Usage Examples

### Example 1: Discover New Hip-Hop Artists
```
Keywords: "underground hip hop, indie rap, alternative hip hop"
Max Results: 30
Expected: 90 URLs

Results:
- Step 1: 90 URLs found
- Step 2: 87 artists scraped (3 failed)
- Step 3: 87 genres added
- Step 4: 82 imported (5 duplicates)

Tags Applied: "hip-hop", "apify-feb-2026"
```

### Example 2: Import from Playlist
```
1. Copy 50 URLs from Spotify playlist
2. Paste in Step 1
3. Skip discovery
4. Run Steps 2-4
5. Import all 50
```

### Example 3: Genre-Only Update
```
1. Have URLs from previous run
2. Skip to Step 3
3. Run genre scraper
4. Merge with existing data
5. Update artists
```

---

## ðŸ“ Database Fields Populated

### Always Populated
- âœ… name
- âœ… spotify_url
- âœ… spotify_monthly_listeners
- âœ… track_count
- âœ… source = 'apify_pipeline'
- âœ… source_batch = 'apify-YYYY-MM-DD'

### Usually Populated (70-90%)
- âœ… social_links (JSON with Instagram, YouTube, etc.)
- âœ… instagram_handle
- âœ… image_url
- âœ… country

### Sometimes Populated (40-60%)
- âš ï¸ biography
- âš ï¸ genres (if Step 3 run)

### Rarely Populated
- âš ï¸ email (needs enrichment)
- âš ï¸ website (extracted from social links)

---

## ðŸ”‘ Environment Variables

```env
# Required for scraping dashboard
APIFY_TOKEN=your_apify_token

# Stored in database (not env var)
# - Actor IDs configurable in Settings
```

---

## âœ… Quality Checklist

- [x] 4-step stepper UI
- [x] Keyword discovery
- [x] Direct URL paste
- [x] Core data scraping
- [x] Genre enrichment (optional)
- [x] Data merging by Spotify ID
- [x] Review table with selection
- [x] Summary statistics
- [x] Tag auto-application
- [x] Duplicate detection
- [x] Bulk import
- [x] Admin-only access
- [x] Settings configuration
- [x] Sidebar integration

---

## ðŸŽ‰ Platform Status

**Phase 1**: âœ… Artist Management
**Phase 2**: âœ… Enrichment (72% hit rate)
**Phase 3**: âœ… Deal Pipeline
**Phase 4**: âœ… AI SDR System
**Phase 5**: âœ… Outreach & Instantly
**Phase 6**: âœ… Admin Scraping Dashboard â† **Just Completed!**

**Remaining**: Analytics dashboard, Scout management

---

**The scraping dashboard is now live!** Import hundreds of artists with one click! ðŸŽµ
